# -*- coding: utf-8 -*-
"""Predicting Taxi Fare_New York City

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eEC9JNzE7u2DVkZ2ojNcwkKZ4GcJtGJo
"""

#Installing Facebook Prophet library

!pip install fbprophet

!pip install pystan 
!pip install pmdarima

#Importing Python libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.simplefilter ('ignore')
from fbprophet import Prophet

#Mounting Google drive to save data for the prediction
from google.colab import drive

drive.mount('/content/drive')

#path = 'drive/My Drive/DATA5000 PROJECT/train.csv' Reading yellow taxi rides

df = pd.read_csv(r'drive/My Drive/DATA5000 PROJECT/train.csv', nrows= 300000, parse_dates=['pickup_datetime'] )  
#Reading data in DataFrame (df)

#Uploading traffic dataset

df_traffic = pd.read_csv (r'drive/My Drive/DATA5000 PROJECT/Traffic_Volume_Counts__2014-2019_.csv')

#Uploading weather dataset

df_weather = pd.read_csv (r'drive/My Drive/DATA5000 PROJECT/Weather.csv')

df_weather.head(5)

df_traffic.head(5)

df_traffic['mean'] = df_traffic.mean(axis=1) #Mean value of the hourly traffic

#df_t.drop('Segment ID',  axis=1).apply(lambda x: x.mean())

# it drops the Region column
#df_t.drop('Segment ID', axis=1,inplace=True)

df_traffic.head(5)

# add time information to the traffic table
df_traffic['Date'] = pd.to_datetime(df_traffic['Date'])


df_traffic['year'] = df_traffic["Date"].apply(lambda t: t.year)
df_traffic['weekday'] = df_traffic["Date"].apply(lambda t: t.weekday())
df_traffic['month'] = df_traffic['Date'].dt.month
df_traffic['day'] = df_traffic['Date'].dt.day
df_traffic['hour'] = df_traffic["Date"].apply(lambda t: t.hour)

df_traffic['ds'] = pd.DatetimeIndex((df_traffic['year'].apply(str) + '-' + df_traffic['month'].apply(str) + '-' + df_traffic['day'].apply(str))) #Concatenating the dates

df_traffic.head()

#Processing traffic dataset

df_traffic = df_traffic.groupby('ds').mean()

df_traffic



df_traffic = df_traffic.reset_index()[['ds','mean']].rename({'mean':'avg-traffic'}, axis= 'columns')

df_traffic #final dataset for traffic on the average

# given the following data

df_traffic = pd.DataFrame(df_traffic)

# convert the datetime column to a datetime type and assign it back to the column

df_traffic.ds = pd.to_datetime(df_traffic.ds)
df_traffic.plot(x='ds')
plt.show()

sns.scatterplot(data = df_traffic)

df_weather['pickup_datetime'] = pd.to_datetime(df_weather['pickup_datetime'])

# add time information
df_weather['year'] = df_weather["pickup_datetime"].apply(lambda t: t.year)
df_weather['weekday'] = df_weather["pickup_datetime"].apply(lambda t: t.weekday())
df_weather['month'] = df_weather['pickup_datetime'].dt.month
df_weather['day'] = df_weather['pickup_datetime'].dt.day
df_weather['hour'] = df_weather["pickup_datetime"].apply(lambda t: t.hour)

df_weather['ds'] = pd.DatetimeIndex((df_weather['year'].apply(str) + '-' + df_weather['month'].apply(str) + '-' + df_weather['day'].apply(str))) #Concatenating the dates

df_weather = df_weather.groupby('ds')['tempm','pickup_datetime'].mean()

df_weather

df_weather.plot()
plt.title('Weather Condition for the year by temperature')
plt.figure(figsize=(10,500))

df.info() #Yellow taxi dataset contaning drop-off and pick-up

train_df = df #Keeping a copy of the dataframe

train_df.dtypes

train_df = train_df[train_df['fare_amount'] >=0] #Eliminate a situation where the value of fare is less than zero

sns.distplot(train_df['fare_amount'], kde = False) #Ploting the histogram chart of fare amount
#plt.xlim(50,5)

sns.lineplot(y = train_df['fare_amount'], x = train_df['passenger_count']) #Exploring the relationship between passenger count and fare
#plt.xlim(50,5)

train_df.corr()

sns.distplot(train_df[train_df['fare_amount']<75]['fare_amount'], kde = False) #Ploting the histogram chart of fare amount for values less than 75

train_df.describe() #preview what the dataset look like

train_df.isnull().sum() #checking if there is any null values in the dataframe

train_df = train_df.dropna() #Dropping a null entries

train_df.isnull().sum()

train_df #Cleaned dataset from null value in the entry

#loading the train dataset

test_df2 = pd.read_csv(r'drive/My Drive/DATA5000 PROJECT/test.csv')  
#Reading data in DataFrame (df)

Long = - 73.935242
Lat = 40.730610 
#Longitude and Latitude of the city center of New York City



"""Defining the boundaries of the test area"""

print(min(test_df2['pickup_longitude'].min(),test_df2['dropoff_longitude'].min())) #Finding the minimum value of the longitude test dataset

print(max(test_df2['pickup_longitude'].max(),test_df2['dropoff_longitude'].max()))

print(min(train_df['pickup_longitude'].min(),train_df['dropoff_longitude'].min())) #Finding the minimum value of the longitude test dataset

print(max(train_df['pickup_longitude'].max(),train_df['dropoff_longitude'].max()))

print(min(test_df2['pickup_latitude'].min(),test_df2['dropoff_latitude'].min()))

print(max(test_df2['pickup_latitude'].max(),test_df2['dropoff_latitude'].max()))

print(min(train_df['pickup_latitude'].min(),train_df['dropoff_latitude'].min()))

print(max(train_df['pickup_latitude'].max(),train_df['dropoff_latitude'].max()))

"""Selecting a boundary area"""

# this function is to select the boundaries and will be used for both test and train dataset
def select_within_boundingbox(df, BBa):
    return (df.pickup_longitude >= BBa[0]) & (df.pickup_longitude <= BBa[1]) & \
           (df.pickup_latitude >= BBa[2]) & (df.pickup_latitude <= BBa[3]) & \
           (df.dropoff_longitude >= BBa[0]) & (df.dropoff_longitude <= BBa[1]) & \
           (df.dropoff_latitude >= BBa[2]) & (df.dropoff_latitude <= BBa[3])

# load image of NYC map
BB = (-74.5, -72.8, 40.5, 41.8)

pip install --upgrade certifi

import ssl
ssl._create_default_https_context = ssl._create_unverified_context

nyc_map = plt.imread('https://aiblog.nl/download/nyc_-74.5_-72.8_40.5_41.8.png')

# load extra image to zoom in on NYC
BB_Zoom = (-74.3, -73.7, 40.5, 40.9)
nyc_map_zoom = plt.imread('https://aiblog.nl/download/nyc_-74.3_-73.7_40.5_40.9.png')

train_df = train_df[select_within_boundingbox(train_df, BB)]

print('Old size: %d' % len(train_df))
train_df = train_df[select_within_boundingbox(train_df, BB)]
print('New size: %d' % len(train_df))

"""Plot data on map"""

# this function will be used more often to plot data on the NYC map
def plot_on_map(df, BB, nyc_map, s=10, alpha=0.2):
    fig, axs = plt.subplots(1, 2, figsize=(16,10))
    #axs[0].scatter(df["pickup_longitude"], df["pickup_latitude"], alpha = alpha, c='r', s=s)
    axs[0].scatter(df.pickup_longitude, df.pickup_latitude, zorder=1, alpha=alpha, c='r', s=s)
    
    axs[0].set_xlim((BB[0], BB[1]))
    axs[0].set_ylim((BB[2], BB[3]))
    axs[0].set_title('Pickup locations')
    axs[0].imshow(nyc_map, zorder=0, extent=BB)
    #axs[1].scatter(df["dropoff_longitude"], df["dropoff_latitude"] , alpha = alpha, c='b', s=s)
    axs[1].scatter(df.dropoff_longitude, df.dropoff_latitude, zorder=1, alpha=alpha, c='r', s=s)
    axs[1].set_xlim((BB[0], BB[1]))
    axs[1].set_ylim((BB[2], BB[3]))
    axs[1].set_title('Dropoff locations')
    axs[1].imshow(nyc_map, zorder=0, extent=BB)

# plot training data on map
plot_on_map(train_df, BB, nyc_map, s=1, alpha=0.1)

# plot test data on map
plot_on_map(test_df2, BB, nyc_map, alpha=1.0, s=20)

"""Data Visualization of the train dataset"""

def plot_hires(df, BB, figsize=(12, 12), ax=None, c=('r', 'b')):
    if ax == None:
        fig, ax = plt.subplots(1, 1, figsize=figsize)

    idx = select_within_boundingbox(df, BB)
    ax.scatter(df[idx].pickup_longitude, df[idx].pickup_latitude, c=c[0], s=0.01, alpha=0.5)
    ax.scatter(df[idx].dropoff_longitude, df[idx].dropoff_latitude, c=c[1], s=0.01, alpha=0.5)

plot_hires(train_df, (-74.1, -73.7, 40.6, 40.9))
plot_hires(train_df, (-74, -73.95, 40.7, 40.8))

plot_hires(test_df2, (-74.1, -73.7, 40.6, 40.9))
plot_hires(test_df2, (-74, -73.95, 40.7, 40.8)) #To further view the look of the graph

train_df.head()

test_df2.head()

# add time information
train_df['year'] = train_df["pickup_datetime"].apply(lambda t: t.year)
train_df['weekday'] = train_df["pickup_datetime"].apply(lambda t: t.weekday())
train_df['month'] = train_df['pickup_datetime'].dt.month
train_df['day'] = train_df['pickup_datetime'].dt.day
train_df['hour'] = train_df["pickup_datetime"].apply(lambda t: t.hour)

train_df.head()

df = train_df #duplicating the dataset

df.dtypes

#concatinating the data as string to get the results to create a new field as ds

df['ds'] = pd.DatetimeIndex((df['year'].apply(str) + '-' + df['month'].apply(str) + '-' + df['day'].apply(str)))

df.head()

train_df.head()

"""Distance and Time Visualization

The longer the distance between pickup and dropoff locations, the higher the fare.
Some trips, like to/from an airport are fixed fee.
Fare at night is different from the day time.

**Formula to be used for calculating the distance between latitude and longitude**
"""

def distance(lat1, lon1, lat2, lon2):
  p = 0.017453292519943295 # Pi/180
  a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p))/2
  return 0.6213712 * 12742 * np.arcsin(np.sqrt(a))

"""The longer the distance between pickup and dropoff location, higher the fare. Adding new column to dataframe with distance in miles
In Calculating the distance

"""

train_df["distance_in_miles"] = distance(train_df["pickup_latitude"], train_df["pickup_longitude"], 
                                      train_df["dropoff_latitude"], train_df["dropoff_longitude"])

train_df.head() #view the dataframe

train_df["distance_in_miles"].hist(bins=50, figsize=(15,6))
plt.title("Ride distance in miles");

train_df.groupby('passenger_count')['distance_in_miles','fare_amount'].mean() #visualizing the effect of categories

"""Scatter Plot distance vs Fare. Visualizing the relevance in the data"""

fig, axs = plt.subplots(1, 2, figsize=(16,6))
axs[0].scatter(train_df["distance_in_miles"], train_df["fare_amount"], alpha=0.2)
axs[0].set_xlabel("distance in mile")
axs[0].set_ylabel("Fare in $USD")
axs[0].set_title("All Dataset")

# Zoom-in some part of the data
idx = ((train_df['distance_in_miles'] < 15) & (train_df["fare_amount"] < 100))
axs[1].scatter(train_df[idx]["distance_in_miles"], train_df[idx]["fare_amount"], alpha=0.2)
axs[1].set_xlabel("distance in mile")
axs[1].set_ylabel("Fare in $USD")
axs[1].set_title("Zoom in on distance < 15 miles and fare < $100")

# remove datapoints with distance <0.05 miles
idx = (train_df["distance_in_miles"] >= 0.05)
print('Old size: %d' % len(train_df))
train_df = train_df[idx]
print('New size: %d' % len(train_df))

"""JF Kennedy International Airport coordinate"""

jfk = (-73.7822222222,40.6441666667)
nyc = (-74.0063889, 40.7141667)

def plot_location_fare(loc, name, range=1.5):
    # select all datapoints with dropoff location within range of airport
    fig, axs = plt.subplots(1,2, figsize=(14,5))
    idx = (distance(train_df["pickup_latitude"], train_df["pickup_longitude"], loc[1], loc[0]) < range)
    train_df[idx]["fare_amount"].hist(bins = 100, ax=axs[0])
    axs[0].set_xlabel("Fare $USD")
    axs[0].set_title("Histogram pickup location within {} miles of {}".format(range, name))
    
    idx = (distance(train_df["dropoff_latitude"], train_df["dropoff_longitude"], loc[1], loc[0]) < range)
    train_df[idx]["fare_amount"].hist(bins=100, ax=axs[1])
    axs[1].set_xlabel("Fare $USD")
    axs[1].set_title("Histogram dropoff location within {} miles of {}".format(range, name))

plot_location_fare(jfk, 'JFK Airport')

#Other major locations in NYC
cnh = (-74.017, 40.714) #Conrad Hotel New York
ewr = (-74.175, 40.69) #Newark Liberty International Airport https://www.travelmath.com/airport/EWR
lgr = (-73.87, 40.77) #Laguardia Airport, https://www.travelmath.com/airport/LGA

plot_location_fare(cnh, 'Conrad Hotel')

plot_location_fare(ewr, 'Newark Airport')

plot_location_fare(lgr, 'LaGuardia airport')

"""Night Fare is different from day time"""

train_df["fare_per_mile"] = train_df["fare_amount"] / train_df["distance_in_miles"]

train_df["fare_per_mile"].describe()

idx = (train_df["distance_in_miles"] < 3) & (train_df["fare_amount"] < 100)
plt.scatter(train_df[idx]["distance_in_miles"], train_df[idx]["fare_per_mile"])
plt.title("Scatter plot of fare against distance in miles")
plt.xlabel("distance in mile")
plt.ylabel("fare per distance in mile")

"""Plotting a Pivot Table"""

train_df.pivot_table("fare_per_mile", index="hour", columns="ds") #Check the result of this table

train_df.pivot_table("fare_per_mile", index="hour", columns="year").plot(figsize=(14,6))
plt.title("Hourly fare rate between 2009 and 2015")
plt.ylabel("Fare in $USD per mile")

"""**Fare and Time Dependency Per Year**"""

#Fitting the dataset to be trained

from sklearn.linear_model import LinearRegression

# plot all years
for year in train_df["year"].unique():
    
    # create figure
    fig, axs = plt.subplots(4, 6, figsize=(18, 10))
    axs = axs.ravel()
    
    # plot for all hours
    
    for h in range(24):
        idx = (train_df["distance_in_miles"] < 15) & (train_df["fare_amount"] < 100) & (train_df["hour"] == h) & \
              (train_df["year"] == year)
        axs[h].scatter(train_df[idx]["distance_in_miles"], train_df[idx]["fare_amount"], alpha=0.2, s=1)
        axs[h].set_xlabel('distance miles')
        axs[h].set_ylabel('fare $USD')
        axs[h].set_xlim((0, 15))
        axs[h].set_ylim((0, 70))
        
        model = LinearRegression(fit_intercept=False)
        
        X, y = train_df[idx]["distance_in_miles"].values.reshape(-1,1), train_df[idx]["fare_amount"].values
        model.fit(X, y)
        xx = np.linspace(0.1, 25, 100)
        axs[h].plot(xx, model.predict(xx.reshape(-1,1)), '--', c='r', lw=2)
        
    plt.suptitle("Year = {}".format(year))
    plt.tight_layout(rect=[0, 0, 1, 0.95]);

"""**Relevance of direction for calculation of fare amount**"""

train_df["delta_lon"] = train_df["pickup_longitude"] - train_df["dropoff_longitude"]
train_df["delta_lat"] = train_df["pickup_latitude"] - train_df["dropoff_latitude"]

"""**Select trips in Manhattan**"""

BB_manhattan = (-74.025, -73.925, 40.7, 40.8)
idx_manhattan = select_within_boundingbox(train_df, BB_manhattan)

plt.figure(figsize=(14,8))
plt.scatter(train_df[idx_manhattan]["delta_lon"], train_df[idx_manhattan]["delta_lat"], s=0.5, alpha=1.0,
            c=np.log1p(train_df[idx_manhattan]["fare_amount"]), cmap="afmhot")
plt.colorbar()
plt.xlabel('pickup_longitude - dropoff_longitude')
plt.ylabel('pickup_latitude - dropoff_latitude')
plt.title('Distance by coordinate with fare_amount')

"""**Looks like direction of the trip seems to matter. Direction of a trip, from 180 to -180 degrees. Horizontal axes = 0**"""

def calculate_direction(d_lon, d_lat):
    result = np.zeros(len(d_lon))
    l = np.sqrt(d_lon**2 + d_lat**2)
    result[d_lon>0] = (180/np.pi)*np.arcsin(d_lat[d_lon>0]/l[d_lon>0])
    idx = (d_lon<0) & (d_lat>0)
    result[idx] = 180 - (180/np.pi)*np.arcsin(d_lat[idx]/l[idx])
    idx = (d_lon<0) & (d_lat<0)
    result[idx] = -180 - (180/np.pi)*np.arcsin(d_lat[idx]/l[idx])
    return result

train_df['direction'] = calculate_direction(train_df.delta_lon, train_df.delta_lat)

# plot histogram of directions
plt.figure(figsize=(10,6))
train_df[idx_manhattan].direction.hist(bins=180)
plt.xlabel('direction (degrees)')
plt.title('Histogram direction (Manhattan)')

# plot direction vs average fare amount
fig, ax = plt.subplots(1, 1, figsize=(14,6))
direc = pd.cut(train_df[idx_manhattan]['direction'], np.linspace(-180, 180, 40))

train_df[idx_manhattan].pivot_table('fare_amount', index=[direc], columns='year', aggfunc='mean').plot(ax=ax)

plt.xlabel('direction (degrees)')
plt.xticks(range(36), np.arange(-170, 190, 10))
plt.ylabel('average fare amount $USD');

"""**Fare varies with pickup location**"""

# add new column to dataframe with distance in mile
train_df['distance_to_center'] = distance(nyc[1], nyc[0], train_df["pickup_latitude"], train_df["pickup_longitude"])

new_train_df = train_df.groupby('ds')['distance_in_miles','fare_amount', 'fare_per_mile'].mean() #Grouping the dataset based on date

fig, axs = plt.subplots(1, 2, figsize=(16,6))
im = axs[0].scatter(train_df["distance_to_center"], train_df["distance_in_miles"], c=np.clip(train_df["fare_amount"], 0, 100), 
                     cmap='viridis', alpha=1.0, s=1)

axs[0].set_xlabel('pickup distance from NYC center')
axs[0].set_ylabel('distance miles')
axs[0].set_title('All data')

cbar = fig.colorbar(im, ax=axs[0])
cbar.ax.set_ylabel('fare_amount', rotation=270)


idx = (train_df["distance_to_center"] < 15) & (train_df["distance_in_miles"] < 35)
im = axs[1].scatter(train_df[idx]["distance_to_center"], train_df[idx]["distance_in_miles"], 
                     c=np.clip(train_df[idx]["fare_amount"], 0, 100), cmap='viridis', alpha=1.0, s=1)
axs[1].set_xlabel('pickup distance from NYC center')
axs[1].set_ylabel('distance miles')
axs[1].set_title('Zoom in')
cbar = fig.colorbar(im, ax=axs[1])
cbar.ax.set_ylabel('fare_amount', rotation=270);

"""There is a lot of 'green' dots, which is about $50 to $60 fare amount near 13 miles distance of NYC center of distrance of trip. This could be due to trips from/to JFK airport
Baseline Model and Submission

**Dataset to be passed into the trained model**
"""

train_df['year']

"""Building model for the prediction after feature engineering
**Using Prophet to carry out the forcasting**
"""

new_train_df

new_df = new_train_df.reset_index()[['ds','distance_in_miles','fare_amount','fare_per_mile']].rename({'fare_amount':'y'}, axis= 'columns')

new_df

new_df_Pr = new_df.drop(['fare_per_mile'], axis = 1)

new_df_Pr.isnull().sum()

m = Prophet(interval_width = 0.95) #Fitting our model

m.add_regressor('distance_in_miles', standardize= False)

model = m.fit(new_df_Pr)

future['distance_in_miles'] = new_df_Pr['distance_in_miles']

future['distance_in_miles'] = new_df_Pr['distance_in_miles']

#Prophet prediction model
future = m.make_future_dataframe(periods=300, freq='D')

future.tail()

forcast = m.predict(future)
forcast.head()

forcast.tail()

#Extracting the actual prediction based on the passed columns

forcast[['ds','yhat']]

fig1 = m.plot(forcast)

fig = m.plot_components(forcast)

from fbprophet.plot import plot_plotly 
import plotly.offline as py

fig = plot_plotly(m, forcast)

py.iplot(fig)

from fbprophet.diagnostics import cross_validation
df_cv = cross_validation(m, initial='730 days', horizon = '365 days')

df_cv.head()

# Validating the result of the test
from fbprophet.diagnostics import performance_metrics
df_p = performance_metrics(df_cv)
df_p.head()

df_p.mean()

pd.concat([new_df_Pr.set_index('ds')['y'], forcast.set_index('ds')['yhat']], axis=1).plot()